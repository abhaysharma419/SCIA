# Schema Change Impact Analyzer (SCIA)

**Predict schema change risks before they break production.**

SCIA analyzes SQL schema changes and tells you:
- âœ… What will break
- âœ… How risky it is (LOW/MEDIUM/HIGH)
- âœ… Why it matters

Works with JSON exports, SQL migration files, or live warehouse connections.

---

## ğŸš€ Quick Start

### 1. Install

```bash
pip install scia-core
```

### 2. Prepare Schema Files

Create two JSON files representing your schema before and after the change:

**`before_schema.json`** â€” Original schema
```json
[
  {
    "schema_name": "analytics",
    "table_name": "customers",
    "columns": [
      {
        "column_name": "customer_id",
        "data_type": "INT",
        "is_nullable": false,
        "ordinal_position": 1
      },
      {
        "column_name": "email",
        "data_type": "VARCHAR",
        "is_nullable": true,
        "ordinal_position": 2
      }
    ]
  }
]
```

**`after_schema.json`** â€” Modified schema (e.g., removed `email` column)
```json
[
  {
    "schema_name": "analytics",
    "table_name": "customers",
    "columns": [
      {
        "column_name": "customer_id",
        "data_type": "INT",
        "is_nullable": false,
        "ordinal_position": 1
      }
    ]
  }
]
```

### 3. Run Analysis

**JSON Mode (Offline):**
```bash
scia analyze --before before_schema.json --after after_schema.json --format markdown
```

**SQL Mode (Migration Analysis):**
Analyze risk of applying a SQL migration to an existing schema (JSON or DB).
```bash
# Apply migration.sql to schema in base_schema.json
scia analyze --before base_schema.json --after migration.sql --format markdown

# Specify dialect for SQL parsing (currently only snowflake fully supported)
scia analyze --before base_schema.json --after migration.sql --dialect snowflake --format markdown
```
*Supported ALTER operations:* `ADD COLUMN`, `DROP COLUMN`, `RENAME COLUMN`, `ALTER COLUMN (TYPE/NULLABILITY)`.

**Database Mode (Live):**
```bash
scia analyze --before PROD.ANALYTICS --after DEV.ANALYTICS --warehouse snowflake --format markdown
```

### 4. Get Risk Assessment

Output (Markdown):
```
RISK: HIGH
Classification: HIGH
Risk Score: 80

Findings:
1. COLUMN_REMOVED (Severity: HIGH)
   - Column 'email' removed from table 'customers'
   - Evidence: table=customers, column=email
```

> [!NOTE]
> **New to v0.2?** Check out the [Advanced Usage Guide](docs/USAGE_V02.md) for SQL migration analysis, live database connections, and dependency analysis features.

---

## ğŸ“‹ Common Use Cases

### Use Case 1: Column Removal

**Scenario:** Remove a column you think is unused

```bash
scia analyze \
  --before before_schema.json \
  --after after_schema.json \
  --format markdown
```

**Output:** 
- âœ… Detects if downstream views depend on this column
- âœ… Warns about join key changes
- âœ… Scores risk (HIGH if widely used)

### Use Case 2: Type Change

**Scenario:** Change INT column to STRING

```bash
# before_schema.json: "data_type": "INT"
# after_schema.json: "data_type": "VARCHAR"

scia analyze \
  --before before_schema.json \
  --after after_schema.json \
  --format json
```

**Output:** 
- âœ… Identifies type incompatibility
- âœ… Warns about casting issues
- âœ… Risk: MEDIUM (may break queries)

### Use Case 3: Nullability Change

**Scenario:** Make nullable column NOT NULL

```bash
# before_schema.json: "is_nullable": true
# after_schema.json: "is_nullable": false

scia analyze \
  --before before_schema.json \
  --after after_schema.json \
  --format json
```

**Output:**
- âœ… Detects NOT NULL constraint
- âœ… Warns about NULL values in production
- âœ… Risk: MEDIUM (data quality issue)

---

## ğŸ“Š Output Formats

### Markdown (Human-Readable)

```bash
scia analyze --before before_schema.json --after after_schema.json --format markdown
```

**Output:**
```
# Risk Assessment: HIGH

## Findings (3)

| Finding Type | Severity | Risk | Evidence |
|---|---|---|---|
| COLUMN_REMOVED | HIGH | 80 | {table: users, column: user_id} |
| COLUMN_TYPE_CHANGED | MEDIUM | 40 | {...} |
| ...| | | |
```

### JSON (Machine-Readable)

```bash
scia analyze --before before_schema.json --after after_schema.json --format json
```

**Output:**
```json
{
  "risk_score": 120,
  "classification": "HIGH",
  "findings": [
    {
      "finding_type": "COLUMN_REMOVED",
      "severity": "HIGH",
      "base_risk": 80,
      "evidence": {"table": "users", "column": "user_id"},
      "description": "Column 'user_id' removed from table 'users'."
    }
  ]
}
```

---

## ğŸ”§ CLI Reference

### Basic Command

```bash
scia analyze --before <before.json> --after <after.json> [options]
```

### Options

| Option | Required | Example | Description |
|--------|----------|---------|-------------|
| `--before` | âœ… | `before.json` | Original schema (JSON, SQL, or SCHEMA.TABLE) |
| `--after` | âœ… | `after.json` | Modified schema (JSON, SQL, or SCHEMA.TABLE) |
| `--warehouse` | âŒ | `snowflake` | Warehouse type (required for DB mode) |
| `--conn-file` | âŒ | `config.yaml` | Connection config file |
| `--dependency-depth`| âŒ | `3` | Max depth for dependency analysis (1-10) |
| `--dialect` | âŒ | `snowflake` | SQL dialect for parsing (snowflake, postgres, mysql, bigquery, databricks, redshift). Default: snowflake. **Note: Only snowflake dialect is fully supported currently.** |
| `--format` | âŒ | `json` or `markdown` | Output format (default: json) |
| `--fail-on` | âŒ | `HIGH` | Exit code 1 if risk meets threshold |

### Exit Codes

- `0` â€” Success (risk below threshold or below `--fail-on`)
- `1` â€” Risk matches `--fail-on` threshold

### Example: Use in CI/CD

```bash
# Fail CI if HIGH risk detected
scia analyze --before before.json --after after.json --fail-on HIGH
```

---

## ğŸ’¡ Examples

### Example 1: Safe Column Addition

**before.json:**
```json
[{"schema_name": "db", "table_name": "orders", "columns": [...]}]
```

**after.json:**
```json
[{"schema_name": "db", "table_name": "orders", "columns": [..., {"column_name": "order_notes", "data_type": "VARCHAR", "is_nullable": true, "ordinal_position": 5}]}]
```

**Command:**
```bash
scia analyze --before before.json --after after.json --format markdown
```

**Result:** âœ… `RISK: LOW` â€” New nullable column is safe

---

### Example 2: Risky Column Removal

**before.json:**
```json
[{"schema_name": "db", "table_name": "users", "columns": [{"column_name": "user_id", ...}, ...]}]
```

**after.json:**
```json
[{"schema_name": "db", "table_name": "users", "columns": [...]}]  # user_id removed
```

**Command:**
```bash
scia analyze --before before.json --after after.json --format markdown
```

**Result:** âš ï¸ `RISK: HIGH` â€” Primary key removed, will break joins

---

## ğŸ“‚ Project Structure

```
SCIA/
â”œâ”€â”€ .github/copilot-instructions.md    (AI agent guidance)
â”œâ”€â”€ AI_QUICK_REFERENCE.md              (Quick reference)
â”œâ”€â”€ README.md                          (This file)
â”‚
â”œâ”€â”€ docs/                              (Documentation)
â”‚   â”œâ”€â”€ design.md                      (Architecture)
â”‚   â”œâ”€â”€ REQUIREMENTS.md                (Functional spec)
â”‚   â””â”€â”€ FOLDER_STRUCTURE.md            (Project organization)
â”‚
â”œâ”€â”€ scia/                              (Source code)
â”‚   â”œâ”€â”€ cli/main.py                    (Command-line interface)
â”‚   â”œâ”€â”€ core/                          (Analysis engine)
â”‚   â”‚   â”œâ”€â”€ diff.py                    (Schema comparison)
â”‚   â”‚   â”œâ”€â”€ rules.py                   (Risk rules)
â”‚   â”‚   â””â”€â”€ risk.py                    (Risk scoring)
â”‚   â”œâ”€â”€ models/                        (Data models)
â”‚   â”œâ”€â”€ output/                        (Renderers)
â”‚   â””â”€â”€ sql/                           (SQL parsing)
â”‚
â”œâ”€â”€ tests/                             (Tests)
â”‚   â”œâ”€â”€ test_diff.py
â”‚   â”œâ”€â”€ test_rules.py
â”‚   â””â”€â”€ fixtures/                      (Test data)
â”‚       â”œâ”€â”€ before.json
â”‚       â”œâ”€â”€ after.json
â”‚       â””â”€â”€ after_medium.json
â”‚
â””â”€â”€ pyproject.toml                     (Package config)
```

---

## ğŸ—ï¸ What SCIA Does (v0.2)

**Detects:**
- Column removal, type changes, nullability changes
- **JOIN key breakage** (High Risk)
- **GROUP BY grain changes** (Medium Risk)
- **Downstream view breakage** (Transitive impact)

**Scores risk as:**
- **LOW** (<30) â€” Safe to deploy
- **MEDIUM** (30-69) â€” Review recommended
- **HIGH** (â‰¥70) â€” Likely to break systems

**Outputs:**
- JSON with `impact_detail`
- Markdown with "Downstream Impact" tables

---

## ğŸš« What SCIA Does NOT Do

- âŒ Modify your schema
- âŒ Connect to your warehouse (uses JSON exports)
- âŒ Require a metadata catalog
- âŒ Lock you into a vendor
- âŒ Support dbt as a requirement (only optional enrichment)

---

## ğŸ› ï¸ For Developers

### Run Tests

```bash
pytest tests/
```

### Run a Specific Test

```bash
pytest tests/test_diff.py -v
```

### Run with Coverage

```bash
pytest tests/ --cov=scia
```

### Develop & Install in Editable Mode

```bash
pip install -e .
```

---

## ğŸ“š Documentation

- **[docs/design.md](docs/design.md)** â€” Architecture & design decisions
- **[docs/REQUIREMENTS.md](docs/REQUIREMENTS.md)** â€” Functional specification
- **[docs/FOLDER_STRUCTURE.md](docs/FOLDER_STRUCTURE.md)** â€” Project organization
- **[.github/copilot-instructions.md](.github/copilot-instructions.md)** â€” AI agent guidance (for developers extending SCIA)

---

## ğŸ¯ Risk Scoring

## ğŸ¯ Risk Scoring

Each change type gets a base risk score:

| Change Type | Base Risk | Why |
|-------------|-----------|-----|
| Column removed | 80 | Breaks joins, aggregations |
| Type changed | 40 | May cause casting errors |
| Nullability changed | 50 | Data quality issues |
| Column added (nullable) | 0 | Safe â€” won't break anything |

**Total risk = Sum of all findings**

- **LOW** (<30): Safe to deploy
- **MEDIUM** (30-69): Review before deploying
- **HIGH** (â‰¥70): Likely to break downstream systems

---

## ğŸ’¡ Tips

### Tip 1: Export Snowflake Schema

To get schema JSON from Snowflake:

```sql
SELECT 
  table_schema as schema_name,
  table_name,
  column_name,
  data_type,
  is_nullable,
  ordinal_position
FROM information_schema.columns
WHERE table_schema = 'ANALYTICS'
ORDER BY table_name, ordinal_position;
```

Export as JSON and use with SCIA.

### Tip 2: Use in CI/CD

Add to your deployment pipeline:

```yaml
# GitHub Actions example
- name: Check schema changes
  run: |
    scia analyze --before before.json --after after.json --fail-on HIGH
    # Job fails if HIGH risk detected
```

### Tip 3: Compare Multiple Scenarios

```bash
# Scenario 1: Remove column
scia analyze --before base.json --after scenario1.json

# Scenario 2: Change type
scia analyze --before base.json --after scenario2.json

# Pick the safer approach
```

---

## ğŸ”§ Troubleshooting

### Connection Issues

**Problem**: `Error: Connection failed to snowflake`

**Solutions**:
1. Verify config file exists: `ls ~/.scia/snowflake.yaml`
2. Check credentials in config file
3. Ensure account identifier is correct (format: `account.region.snowflakecomputing.com`)
4. Use `--conn-file` to specify custom config location

**Example**:
```bash
# Use custom config file
scia analyze --before PROD.ANALYTICS --after DEV.ANALYTICS \
  --warehouse snowflake --conn-file ~/my-config.yaml
```

---

### SQL Parsing Errors

**Problem**: `Warning: Failed to parse SQL in migration.sql`

**Explanation**: SCIA supports CREATE TABLE, ALTER ADD/DROP/MODIFY/RENAME COLUMN. Other DDL is ignored.

**What Happens**: Analysis continues with schema-based rules only (no SQL-specific rules).

**Supported Operations**:
- âœ… `CREATE TABLE`
- âœ… `ALTER TABLE ADD COLUMN`
- âœ… `ALTER TABLE DROP COLUMN`
- âœ… `ALTER TABLE RENAME COLUMN`
- âœ… `ALTER TABLE ALTER COLUMN` (type/nullability changes)
- âŒ Stored procedures, triggers, constraints (ignored)

---

### Dependency Analysis Errors

**Problem**: `Error: max_depth must be 1-10, got 15`

**Solution**: Use `--dependency-depth` with value between 1 and 10:
```bash
scia analyze --before a.json --after b.json --dependency-depth 5
```

---

**Problem**: `Error: DB mode requires --warehouse flag`

**Solution**: Add `--warehouse` when comparing database identifiers:
```bash
scia analyze --before PROD.ANALYTICS --after DEV.ANALYTICS --warehouse snowflake
```

---

### Unsupported Warehouse

**Problem**: `Error: Databricks adapter not yet implemented`

**Current Support**:
- âœ… Snowflake (fully working)
- ğŸ—ï¸ Databricks (planned for v0.3)
- ğŸ—ï¸ PostgreSQL (planned for v0.3)
- ğŸ—ï¸ Redshift (planned for v0.3)

**Workaround**: Export your schema to JSON and use JSON mode:
```bash
scia analyze --before schema.json --after modified.json
```

---

## â“ FAQ

**Q: Can SCIA connect to my warehouse directly?**  
A: Yes! v0.2 supports live connections to Snowflake. Use `--warehouse snowflake` and configure `~/.scia/snowflake.yaml`. See the [Advanced Usage Guide](docs/USAGE_V02.md) for details.

**Q: Do I need dbt?**  
A: No. SCIA works with plain SQL, JSON exports, and warehouse metadata.

**Q: What warehouses are supported?**  
A: v0.2 fully supports Snowflake. Databricks, PostgreSQL, and Redshift are planned for v0.3.

**Q: What if my schema has thousands of columns?**  
A: SCIA analyzes the diff, not absolute size. Performance should be acceptable. Use `--dependency-depth 1` for faster analysis.

**Q: Can I use this in production?**  
A: Yes! v0.2 is production-ready. Start with JSON mode for testing, then enable live warehouse connections. See [docs/USAGE_V02.md](docs/USAGE_V02.md) for best practices.

---

## ğŸ¤ Contributing

We welcome contributions! See [.github/copilot-instructions.md](.github/copilot-instructions.md) for development guide.

Areas for contribution:
- Warehouse adapters (BigQuery, Databricks, PostgreSQL)
- SQL heuristics improvements
- Real-world incident patterns
- Testing edge cases

---

## ğŸ“„ License

Apache 2.0 â€” See LICENSE file

---

## ğŸš€ What's Next?

- **v0.1** âœ…: Core schema diff, risk scoring, JSON-based analysis
- **v0.2** âœ…: SQL migration parsing, live warehouse connectivity (Snowflake), downstream impact analysis
- **v0.3** ğŸ—ï¸: Multi-warehouse support (Databricks, PostgreSQL, Redshift), advanced risk policies, incident pattern matching

---

## ğŸ’¬ Questions?

- Check [docs/USAGE_V02.md](docs/USAGE_V02.md) for advanced v0.2 features
- See [DOCS_INDEX.md](DOCS_INDEX.md) for all documentation
- Read [docs/FOLDER_STRUCTURE.md](docs/FOLDER_STRUCTURE.md) for project layout
- Check [.github/copilot-instructions.md](.github/copilot-instructions.md) for architecture



